# Azure Pentaho Server Docker Project

This project provides a Docker setup for Pentaho Server (PUC). The setup includes Dockerfiles, Docker Compose configurations, and necessary scripts to build and run Pentaho Server in a containerized environment.

## Project Structure

### `dist/azure/pentaho-server/`

This folder contains resources and configurations for running Pentaho Server Docker container with several database variants. For this example we will use MySql database.

- **`pentaho-server-mysql/`**: Contains Docker Compose configurations for running Pentaho Server with MySql database.
    - **`pentaho-server-azure-mysql.yaml`**: Yaml file for deploying Pentaho Server with MySql database into kubernetes cluster.

### `config/`
This folder contains configuration files for the Pentaho Server. It is mounted as a volume in the Docker container to allow customization of the server settings.

### `db_init_mysql/`
This folder should contain the database scripts which needs to be run in the RDS DB Instance.

### `logs/`
This folder is used to store logs generated by the Pentaho Server. It is mounted as a volume in the Docker container to persist logs across container restarts.

### `softwareOverride/`
This folder should contain any configuration files that need to override the default configurations in the Pentaho Server installation.


## Usage

### Prerequisites

- Docker
- Docker Compose

### Building the Docker Image

1. Navigate to the `assemblies/pentaho-sever/` directory.
2. Place the required Pentaho Server distribution software ZIP files in the `assemblies/pentaho-server/stagedArtifacts/` folder.
3. Change the `Dockerfile` `ARG PENTAHO_VERSION` to the desired version of Pentaho Server.
4. Build the Docker image using the following command:
   ```sh
   docker build -t pentaho/pentaho-server:11.x .
   ```
5. tag this image and push it using following commands into ECR
    ```sh
    docker tag <image name> <acr-name>.azurecr.io/<image-name-on-acr>
    docker push <login-server>/<image-name-on-acr>
   ```

### Deploying into Kubernetes and checking logs

## Update yaml Files

Create AKS cluster, Storage Account, File Share and Container Registry, secrets etc.

Update followings in the yaml files

1- PersistentVolume:volumeHandle # Replace with your Azure File Share name
volumeAttributes:shareName # Replace with your Azure File Share name

2- stringData:azurestorageaccountname # Replace with your Azure Storage Account name
stringData:azurestorageaccountkey # Replace with your Storage Account key

3- containers:image Replace with your image

4- env:LICENSE_URL # Replace with your actual license URL

5- volumeMounts:subPath # Update subpath for each mount path

Other values can be changed or keep the name same as YAML file like Namespace, PersistentVolume, PersistentVolumeClaim, ServiceAccount etc..

## Login to AKS Cluster

Run following commands

az aks get-credentials --resource-group <resourceGroup> --name <aks-cluster>
e.g.- az aks get-credentials --resource-group pdia-docker-ackbar --name pdia-docker-ackbar-aks-cluster

## Deploying Pentaho Server

1. `kubectl apply -f /<path>/pentaho-server-azure-mysql.yaml`
   - This command will deploy the Pentaho Server with MySQL database into the Kubernetes cluster.
   - Ensure that the Kubernetes cluster is configured and running.  
2. `kubectl logs pentaho-server-78855f6777-z62w6  -n pentaho-server --all-containers`
   - This command will show the logs of the Pentaho Server pod.
   - Replace `pentaho-server-78855f6777-z62w6` with the actual pod name if it differs.
   - The `-n pentaho-server` flag specifies the namespace where the Pentaho Server is deployed.
3. After the server has started, use the following command to get the external IP to access PUC.
   `kubrctl get services pentaho-loadbalancer-service -n pentaho-server`
4. PUC page can be access via:
   `http://externalIP:8080/pentaho`
   - Replace `externalIP` with the actual external IP address obtained from the previous command.
